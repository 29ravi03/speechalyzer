usePraat=false
useOpenEar=true
useWEKA=true
port=6666
   # identifier for label-lines in annotation file
labelIdentifier=LABELS:
   # identifier for transcription-lines in annotation file
transcriptIdentifier=TRANSCRIPTION:
   # identifier for prediction-lines in annotation file
predictionIdentifier=PREDICTION:
   # extension for audio-accompanying annotation file 
labelFileExtension=txt
audioFormat=wav
garrulous=true
sampleRate=16000
  # Threshold for automated silence detection to stop recording automatically.
  # Raise for noisy environments.
silenceThreshold=250
  # Timeout for automated silence detection in sample vales.
  # I.e. if sample rate=16000 a value of 8000 means half a second. 
speechTimeout=8000
  # Timeout for automated silence detection in sample vales.
  # This is the value before the user starts speaking. 
initialTimeout=32000
# time to wait till result disappears
waitTime=2000
  # If true, microphone has to be pressed to talk (walkie-talkie)
pushToTalk=false
  # If true, microphone has to be clicked to start recording.
  # If both pushToTalk and pushToActivate are false, 
  # automated recording starts after robot finishes talking.
pushToActivate=false
  # if true, buttons are displayed to give positive or negative feedback 
  # for last recording
feedback=true
ressourceDir=res
training=true
   # time in seconds to listen for maximal audio value 
   # while calibrating microphone 
calibrationTime=10
   # whether feature extraction before model building starts from scratch
   # or extracts only files that have no prediction yet.
additiveTraining=false
   # label to category mapping: pairs of category descriptors 
   # assigned to minimum labels, e.g. 1,N;2,NA means category "N" 
   # is assigned for values between 1>=x<2.
   # MUST be in ascending order!
categories=2,N;3,A
   # classifier type, smo, j48 or naiveBayes
classifier=smo

#### pathes
recordingDir=recordings/
testAudioFile=tmp/test.wav
logConfig=./res/logConfigCallcenter.xml
tempFeatFile=tmp/tmpFeat.txt
tmpTxtFile=tmp/tmp.txt
tmpWavFile=tmp/tmp.wav
trainFile=res/train.arff
testFile=res/test.arff
modelFile=res/classifier.model
inputPrompt=res/sounds/input_male.wav
sorryPrompt=res/sounds/sorry_male.wav
notUnderstoodPrompt=res/sounds/notUnderstood_male.wav
forwardPrompt=res/sounds/forward_male.wav
recordings=recordings/
openEarCommand=./tools/SMILExtract.exe
openEarConfig=res/IS10.anger_functs.conf